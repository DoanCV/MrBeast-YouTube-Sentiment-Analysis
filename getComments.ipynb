{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "getComments.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6kgjmJAYB6TTO1r5LfDyO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtK9V3q3me0_"
      },
      "source": [
        "# Import libraries\r\n",
        "import json\r\n",
        "from csv import writer\r\n",
        "from apiclient.discovery import build\r\n",
        "import pandas as pd\r\n",
        "import pickle\r\n",
        "import urllib.request\r\n",
        "import urllib"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeIxZhFZq9J5"
      },
      "source": [
        "# API key from YouTube Data API key\r\n",
        "key = 'AIzaSyCX7iO_x66iiawO6DkeUDPN4yQzfVBLbag'\r\n",
        "videoId = 'PKtnafFtfEo' # Youtube Rewind 2020, Thank God It's Over\r\n",
        "channelId = 'UCX6OQ3DkcsbYNE6H8uQQuVA' # MrBeast "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--zxJNNUq_p_"
      },
      "source": [
        "def build_service():\r\n",
        "    YOUTUBE_API_SERVICE_NAME = \"youtube\"\r\n",
        "    YOUTUBE_API_VERSION = \"v3\"\r\n",
        "    return build(YOUTUBE_API_SERVICE_NAME,\r\n",
        "                 YOUTUBE_API_VERSION,\r\n",
        "                 developerKey=key)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o87R1k2S75oF"
      },
      "source": [
        "def get_comments(part='snippet', \r\n",
        "                 maxResults=100, \r\n",
        "                 textFormat='plainText',\r\n",
        "                 order='time',\r\n",
        "                 allThreadsRelatedToChannelId=channelId,\r\n",
        "                 # videoId=videoId,\r\n",
        "                 csv_filename=\"MrBeast_comments\"\r\n",
        "                 ):\r\n",
        "  \r\n",
        "  # Initialize empty lists which will store the stats on a video\r\n",
        "  comments, commentsId, authorurls, authornames, repliesCount, likesCount, viewerRating, dates, vidIds, totalReplyCounts,vidTitles = [], [], [], [], [], [], [], [], [], [], []\r\n",
        "\r\n",
        "  # Build the serivce\r\n",
        "  service = build_service()\r\n",
        "\r\n",
        "  # Call the API with the service\r\n",
        "  response = service.commentThreads().list(\r\n",
        "        part=part,\r\n",
        "        maxResults=maxResults,\r\n",
        "        textFormat='plainText',\r\n",
        "        order=order,\r\n",
        "        # videoId=videoId\r\n",
        "        allThreadsRelatedToChannelId=channelId\r\n",
        "  ).execute()\r\n",
        "\r\n",
        "  # There is a limit to the amount of data I can pull. \r\n",
        "  # For MrBeast, his channel is quite large and active so this loop will stop running at the quota\r\n",
        "  # Typically I would set a hard cap on the number of comments to pull that is lower than the quota to test if the function is working properly but I have a guide on this API sourced below.\r\n",
        "\r\n",
        "  while response:\r\n",
        "    for item in response['items']:\r\n",
        "            #5 index item for desired data features\r\n",
        "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\r\n",
        "            comment_id = item['snippet']['topLevelComment']['id']\r\n",
        "            reply_count = item['snippet']['totalReplyCount']\r\n",
        "            like_count = item['snippet']['topLevelComment']['snippet']['likeCount']\r\n",
        "            authorurl = item['snippet']['topLevelComment']['snippet']['authorChannelUrl']\r\n",
        "            authorname = item['snippet']['topLevelComment']['snippet']['authorDisplayName']\r\n",
        "            date = item['snippet']['topLevelComment']['snippet']['publishedAt']\r\n",
        "            vidId = item['snippet']['topLevelComment']['snippet']['videoId']\r\n",
        "            totalReplyCount = item['snippet']['totalReplyCount']\r\n",
        "            vidTitle = get_vid_title(vidId)\r\n",
        "\r\n",
        "            #6 append to lists\r\n",
        "            comments.append(comment)\r\n",
        "            commentsId.append(comment_id)\r\n",
        "            repliesCount.append(reply_count)\r\n",
        "            likesCount.append(like_count)\r\n",
        "            authorurls.append(authorurl)\r\n",
        "            authornames.append(authorname)\r\n",
        "            dates.append(date)\r\n",
        "            vidIds.append(vidId)\r\n",
        "            totalReplyCounts.append(totalReplyCount)\r\n",
        "            vidTitles.append(vidTitle)\r\n",
        "\r\n",
        "    try:\r\n",
        "            if 'nextPageToken' in response:\r\n",
        "                response = service.commentThreads().list(\r\n",
        "                    part=part,\r\n",
        "                    maxResults=maxResults,\r\n",
        "                    textFormat=textFormat,\r\n",
        "                    order=order,\r\n",
        "                    # videoId=videoId,\r\n",
        "                    allThreadsRelatedToChannelId=channelId,\r\n",
        "                    pageToken=response['nextPageToken']\r\n",
        "                ).execute()\r\n",
        "            else:\r\n",
        "                break\r\n",
        "    except: break\r\n",
        "  \r\n",
        "  return {\r\n",
        "        'comment': comments,\r\n",
        "        'comment_id': commentsId,\r\n",
        "        'author_url': authorurls,\r\n",
        "        'author_name': authornames,\r\n",
        "        'reply_count' : repliesCount,\r\n",
        "        'like_count' : likesCount,\r\n",
        "        'date': dates,\r\n",
        "        'vidid': vidIds,\r\n",
        "        'total_reply_counts': totalReplyCounts,\r\n",
        "        'vid_title': vidTitles\r\n",
        "    }"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTVDommn75qx"
      },
      "source": [
        "def get_vid_title(vidid):\r\n",
        "    # VideoID = \"LAUa5RDUvO4\"\r\n",
        "    # Usually, the videoID is after the ?v=. This information can also be accessed when clicking share on the video itself.\r\n",
        "    params = {\"format\": \"json\", \"url\": \"https://www.youtube.com/watch?v=%s\" % vidid}\r\n",
        "    url = \"https://www.youtube.com/oembed\"\r\n",
        "    query_string = urllib.parse.urlencode(params)\r\n",
        "    url = url + \"?\" + query_string\r\n",
        "\r\n",
        "    with urllib.request.urlopen(url) as response:\r\n",
        "        response_text = response.read()\r\n",
        "        data = json.loads(response_text.decode())\r\n",
        "        # print(data['title'])\r\n",
        "        return data['title']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqOEvueArFNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130850a7-b7f0-4455-9028-18ebd5c6bf4e"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "    MrBeast_comments = get_comments()\r\n",
        "    df = pd.DataFrame(MrBeast_comments)\r\n",
        "    print(df.shape)\r\n",
        "    print(df.head())\r\n",
        "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\r\n",
        "    df['just_date'] = df['date'].dt.date\r\n",
        "    df.to_csv('./MrBeast_comments.csv')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11258, 10)\n",
            "                                             comment  ...                                          vid_title\n",
            "0  \"I'm sorry, international fans\"\\n\\n*Cries in P...  ...   I Opened A Restaurant That Pays You To Eat At It\n",
            "1                                          Relatable  ...  I Gave People $1,000,000 But ONLY 1 Minute To ...\n",
            "2                      How do you Gus love that crap  ...                 I Went Back To 1st Grade For A Day\n",
            "3  I wouldnâ€™t be surprised if MrBeast became one ...  ...                    I Bought Everything In 5 Stores\n",
            "4                               Chandler:eats a rose  ...  Surprising My Girlfriend With 100,000 Roses Fo...\n",
            "\n",
            "[5 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t13hO1NcmsSI"
      },
      "source": [
        "Credit to William Yang for an explanation of how to get the comments from the YouTube Data API \r\n",
        "https://towardsdatascience.com/how-to-build-your-own-dataset-of-youtube-comments-39a1e57aade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBuOWWdWsajV"
      },
      "source": [
        ""
      ]
    }
  ]
}